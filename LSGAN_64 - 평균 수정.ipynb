{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fbed436",
   "metadata": {
    "id": "3fbed436"
   },
   "source": [
    "- [Generative Adversarial Networks](https://arxiv.org/abs/1406.2661)\n",
    "- [NIPS 2016 Tutorial:\n",
    "Generative Adversarial Networks](https://arxiv.org/pdf/1701.00160.pdf)\n",
    "- [image source](https://xiaohongliu.ca/post/gan/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eeafda3",
   "metadata": {
    "id": "8eeafda3"
   },
   "source": [
    "## Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "146280a7",
   "metadata": {
    "id": "146280a7"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "import numpy as np\n",
    "import math\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d08cc45",
   "metadata": {
    "id": "3d08cc45"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "from torchvision import datasets\n",
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e21bcf72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.1+cu117'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3a7b594",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccc71a1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1e9cc440890>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(2023)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f13e0f",
   "metadata": {
    "id": "36f13e0f"
   },
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9dc5324",
   "metadata": {
    "id": "d9dc5324"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "학습에 사용될 hyperparameter 값들을 넣을 class를 정의합니다.\n",
    "\"\"\"\n",
    "class AttrDict(dict):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(AttrDict, self).__init__(*args, **kwargs)\n",
    "        self.__dict__ = self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb580a80",
   "metadata": {
    "id": "bb580a80"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "GAN model 학습에 사용되는 결과 이미지 저장 경로, 에포크 수, 모델 입력 이미지 크기 등을 정의합니다.\n",
    "\"\"\"\n",
    "config = AttrDict()\n",
    "config.data_path = 'data/resource_2/' \n",
    "config.save_path = 'save/DCGAN_64/'\n",
    "#config.dataset = 'CIFAR10' #CIFAR10 어떠한 데이터셋을 사용하는지\n",
    "config.dataset = 'emoji'\n",
    "\n",
    "config.n_epoch = 200\n",
    "config.log_interval = 150 # loss 출력\n",
    "config.save_interval = 3  # 이미지 출력\n",
    "config.batch_size = 200\n",
    "\n",
    "config.nz = 100\n",
    "config.ngf = 128 # generator oonv filter\n",
    "config.ndf = 128 # discriminator oonv fillter\n",
    "\n",
    "config.learning_rate = 0.00001\n",
    "config.b1 = 0.5\n",
    "config.b2 = 0.999\n",
    "config.img_shape = (3, 64, 64) # c, w, h\n",
    "config.latent_size = 100 # random noise size\n",
    "\"\"\"\n",
    "모델 입력 이미지에 수행할 normalization과 모델 생성 결과 이미지에 수행할 denormalization을 정의합니다.\n",
    "\"\"\"\n",
    "config.augmentation = transforms.Compose([\n",
    "                        transforms.Resize((config.img_shape[1], config.img_shape[2])), #resize\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize(mean=[0.5], std=[0.5]) #normalization\n",
    "                      ])\n",
    "config.denormalize = lambda x: x*0.5+0.5 #denormalization 위의 단계 reverse , 원래의 이미지를 보기 위해 수행함\n",
    "\n",
    "config.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') #cuda에 올리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b950712e",
   "metadata": {
    "id": "b950712e"
   },
   "outputs": [],
   "source": [
    "#지정된 경로의 데이터셋 가져오기 및 저장\n",
    "if not os.path.isdir(config.data_path):\n",
    "    os.makedirs(config.data_path)\n",
    "if not os.path.isdir(os.path.join(config.save_path, config.dataset)):\n",
    "    os.makedirs(os.path.join(config.save_path, config.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29018cfd",
   "metadata": {
    "id": "29018cfd",
    "outputId": "38d86d46-3dc3-4e0f-ad44-7efd5d9a3da3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbc2c6a",
   "metadata": {
    "id": "3fbc2c6a"
   },
   "source": [
    "## Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12be5c3b",
   "metadata": {
    "id": "12be5c3b",
    "outputId": "233c623f-3f2e-4b90-df50-14f3ea03ab33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emoji\n",
      "Dataset ImageFolder\n",
      "    Number of datapoints: 6000\n",
      "    Root location: data/resource_2/\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Resize(size=(64, 64), interpolation=bilinear, max_size=None, antialias=None)\n",
      "               ToTensor()\n",
      "               Normalize(mean=[0.5], std=[0.5])\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "MNIST와 CIFAR-10은 torchvision 라이브러리에서 제공하여 아래와 같이 사용할 수 있습니다.\n",
    "\"\"\"\n",
    "                                 \n",
    "if config.dataset == 'CIFAR10': \n",
    "    train_dataset = datasets.CIFAR10(config.data_path,\n",
    "                                       train=True,\n",
    "                                       download=True,\n",
    "                                       transform=config.augmentation\n",
    "                                     )\n",
    "elif config.dataset == 'emoji': \n",
    "    train_dataset = datasets.ImageFolder(config.data_path,\n",
    "                                         transform=config.augmentation\n",
    "                                     )\n",
    "\n",
    "print(config.dataset)\n",
    "    \n",
    "\"\"\"\n",
    "training set을 Dataloader에 넣습니다. \n",
    "\"\"\"\n",
    "train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True, num_workers = 2)\n",
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71e22dc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2c95863",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "634dcb5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1e9d44569d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(to_pil_image(0.5*img+0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff42e1c",
   "metadata": {},
   "source": [
    "## custom data\n",
    "\n",
    "로컬 디렉토리 image 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91ffa123",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import zipfile\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "688ba052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = ''\n",
    "glob.glob('data/resource/emoji/*')[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a936d8f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x1e9d425a7f0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba67a4c",
   "metadata": {
    "id": "6ba67a4c"
   },
   "source": [
    "## GAN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e81de91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 64, 64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.img_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f3608b5",
   "metadata": {
    "id": "7f3608b5"
   },
   "outputs": [],
   "source": [
    "from torchmetrics.image.fid import FrechetInceptionDistance\n",
    "from torchmetrics.image.inception import InceptionScore\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\"\"\"\n",
    " 일반적으로, GAN에서는 loss가 Discriminator에서부터 Generator로 흐를 때 생길 수 있는 \n",
    " vanishing gradient 현상을 완화하기 위해 Leaky ReLU를 많이 사용합니다. \n",
    "\"\"\"\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "std_scaler = StandardScaler()\n",
    "\n",
    "class Generator(nn.Module): # 입력으로 noise를 받음\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "    \n",
    "        n_ditsributions = 3\n",
    "        \n",
    "        mu = 2 * torch.rand(n_ditsributions) - 1\n",
    "        mu.requires_grad = True\n",
    "        \n",
    "        self.mu = nn.Parameter(mu)\n",
    "        \n",
    "        sigma = 1.0 * torch.ones(n_ditsributions)\n",
    "        sigma.requires_grad = True\n",
    "        \n",
    "        self.sigma = nn.Parameter(sigma)\n",
    "        \n",
    "        self.dconv1 = nn.ConvTranspose2d(config.latent_size, config.ngf*8, 4, stride=1, padding=0)\n",
    "        self.bn1 = nn.BatchNorm2d(config.ngf*8)\n",
    "        #62\n",
    "            \n",
    "        self.dconv2 = nn.ConvTranspose2d(config.ngf*8, config.ngf*4, 4, stride=2, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(config.ngf*4)\n",
    "        #15   \n",
    "            \n",
    "        self.dconv3 = nn.ConvTranspose2d(config.ngf*4, config.ngf*2, 4, stride=2, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(config.ngf*2)\n",
    "            \n",
    "        self.dconv4 = nn.ConvTranspose2d(config.ngf*2, config.ngf,4,stride=2,padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(config.ngf)\n",
    "            \n",
    "        self.dconv5 = nn.ConvTranspose2d(config.ngf, config.img_shape[0], 4,stride=2, padding=1)\n",
    "        \n",
    "    def forward(self, z):\n",
    "        #for i in range(3):\n",
    "        z1 = z  + self.mu[0]\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        #z = (z-torch.mean(z))/(torch.std(z))\n",
    "        \n",
    "        b = z.view(200, 100)\n",
    "        a = b[0].cpu().detach().numpy()\n",
    "        sns.histplot(a, kde=True)\n",
    "        plt.show()\n",
    "        \n",
    "        #print('self.mu',self.mu)\n",
    "        #print('self.sigma',self.sigma)\n",
    "        #idx = torch.randint(0, self.mu.size(0), input.size())\n",
    "        #input = input * self.sigma[idx] + self.mu[idx]\n",
    "        #print(z)\n",
    "        #print(z.shape)\n",
    "        #print(z)\n",
    "        #x = z.view(-1, 100, 1, 1)\n",
    "        #print(z.shape)\n",
    "        \n",
    "        x = F.leaky_relu(self.bn1(self.dconv1(z)), 0.2)\n",
    "        x = F.leaky_relu(self.bn2(self.dconv2(x)), 0.2)\n",
    "        x = F.leaky_relu(self.bn3(self.dconv3(x)), 0.2)\n",
    "        x = F.leaky_relu(self.bn4(self.dconv4(x)), 0.2)\n",
    "        x = torch.tanh(self.dconv5(x))\n",
    "        #img = img.reshape(img.shape[0], *config.img_shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c10c2717",
   "metadata": {
    "id": "c10c2717"
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(config.img_shape[0],config.ndf,4,stride=2,padding=1,bias=False)\n",
    "        self.conv2 = nn.Conv2d(config.ndf,config.ndf*2,4,stride=2,padding=1,bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(config.ndf*2)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(config.ndf*2, config.ndf*4,4,stride=2,padding=1,bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(config.ndf*4)\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(config.ndf*4,config.ndf*8,4,stride=2,padding=1,bias=False)\n",
    "        self.bn4 = nn.BatchNorm2d(config.ndf*8)\n",
    "        \n",
    "        self.conv5 = nn.Conv2d(config.ndf*8,1,4,stride=1,padding=0,bias=False)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = F.leaky_relu(self.conv1(x),0.2)\n",
    "        x = F.leaky_relu(self.bn2(self.conv2(x)),0.2)\n",
    "        x = F.leaky_relu(self.bn3(self.conv3(x)),0.2)\n",
    "        x = F.leaky_relu(self.bn4(self.conv4(x)),0.2)\n",
    "        x = torch.sigmoid(self.conv5(x))\n",
    "        return x.view(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9dc4bf",
   "metadata": {
    "id": "3b9dc4bf"
   },
   "source": [
    "#### Binary Cross Entropy loss between the target and the input probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9684f084",
   "metadata": {
    "id": "9684f084"
   },
   "source": [
    "- [torch.nn.BCELoss](https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fd9eac2a",
   "metadata": {
    "id": "fd9eac2a"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "binary cross entropy loss를 사용하여 adversarial loss를 구현합니다.\n",
    "\"\"\"\n",
    "criterion = nn. BCELoss()\n",
    "\n",
    "\"\"\"\n",
    "Generator와 Discriminator를 각각 정의하고, 상응하는 optimizer도 함께 정의합니다.\n",
    "\"\"\"\n",
    "generator = Generator(config).to(config.device)\n",
    "discriminator = Discriminator(config).to(config.device)\n",
    "\n",
    "optimizer_g = torch.optim.Adam(generator.parameters(), lr=config.learning_rate, betas=(config.b1, config.b2))\n",
    "optimizer_d = torch.optim.Adam(discriminator.parameters(), lr=config.learning_rate, betas=(config.b1, config.b2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b200b0b3",
   "metadata": {
    "id": "b200b0b3"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d209d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#from torchmetrics.image.fid import FrechetInceptionDistance\n",
    "#from torchmetrics.image.inception import InceptionScore\n",
    "#import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "#inception = InceptionScore()\n",
    "\"\"\"\n",
    "Generator와 Discriminator를 번갈아 학습합니다.\n",
    "\"\"\"\n",
    "g_loss_list = []\n",
    "d_loss_list = []\n",
    "for epoch in tqdm(range(config.n_epoch)):\n",
    "    for i, (real_img, _) in enumerate(train_loader):\n",
    "        real_img = real_img.to(config.device)\n",
    "\n",
    "        \"\"\"\n",
    "        adversarial loss에 사용될 ground truth들입니다.\n",
    "        Discriminator에게 있어 실제 이미지는 1, generator가 생성한 fake 이미지는 0을 label로 합니다.\n",
    "        반대로 Generator는 자신이 생성한 fake 이미지의 label이 1이 되게 하여 Discriminator를 fooling 합니다.\n",
    "        \"\"\"\n",
    "        \n",
    "        valid_label = torch.ones((real_img.shape[0], 1), device=config.device, dtype=torch.float32)\n",
    "        #print(valid_label)\n",
    "        #print(valid_label.shape)\n",
    "        fake_label = torch.zeros((real_img.shape[0], 1), device=config.device, dtype=torch.float32)\n",
    "        \n",
    "        # ====================================================#\n",
    "        #                Train Discriminator                  #\n",
    "        # ====================================================#\n",
    "\n",
    "        \"\"\"\n",
    "        Gaussian random noise를 Generator에게 입력하여 fake 이미지들을 생성합니다.\n",
    "        \"\"\"\n",
    "        # 가짜 이미지 생성\n",
    "        #rint(real_img.shape[0])\n",
    "        \n",
    "        z = torch.randn((real_img.shape[0], config.latent_size), device=config.device, dtype=torch.float32)\n",
    "        #print(real_img.shape)\n",
    "        #print(real_img.shape[0])\n",
    "        #print(z.shape)\n",
    "        gen_img = generator(z)\n",
    "        \n",
    "\n",
    "        \"\"\"\n",
    "        Discriminator가 실제 이미지와 Generator가 생성한 이미지를 잘 구별하는지 loss를 계산합니다.\n",
    "        이 때, Generator는 현재 계산된 loss로 학습되지 않으므로, \n",
    "        detach() 함수를 이용하여 생성 이미지를 computation graph에서 분리한 후 Discriminator의 입력으로 넣어줍니다. \n",
    "        \"\"\"\n",
    "        #print(discriminator(real_img))\n",
    "        #print(discriminator(real_img).shape)\n",
    "        ## loss 구함\n",
    "        real_loss = criterion(discriminator(real_img), valid_label)\n",
    "        fake_loss = criterion(discriminator(gen_img.detach()), fake_label) # detach generator는 가중치 업데이트 안함\n",
    "        d_loss = (real_loss + fake_loss) * 0.5\n",
    "        \n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        Discriminator를 업데이트합니다.\n",
    "        \"\"\"\n",
    "        optimizer_d.zero_grad()\n",
    "        d_loss.backward() # 여기서 grediant가 업데이트 안됨\n",
    "        optimizer_d.step()\n",
    "\n",
    "        \n",
    "        # ====================================================#\n",
    "        #                   Train Generator                   #\n",
    "        # ====================================================#\n",
    "\n",
    "        \"\"\"\n",
    "        Gaussian random noise를 Generator에게 입력하여 fake 이미지들을 생성합니다.\n",
    "        \"\"\"\n",
    "        z = torch.randn((real_img.shape[0], config.latent_size), device=config.device, dtype=torch.float32)\n",
    "        gen_img = generator(z)  \n",
    "\n",
    "        \"\"\"\n",
    "        Generator가 Discriminator를 속일 수 있는지 loss를 계산합니다.\n",
    "        \"\"\"\n",
    "        g_loss = criterion(discriminator(gen_img), valid_label) #valid_label로 하여 generator를 학습하게 함\n",
    "        \n",
    " \n",
    "        \n",
    "        \"\"\"\n",
    "        Generator를 업데이트합니다.\n",
    "        \"\"\"\n",
    "        optimizer_g.zero_grad()\n",
    "        g_loss.backward()\n",
    "        optimizer_g.step()\n",
    "        \n",
    "#         if (epoch+1) % config.save_interval == 0:\n",
    "#                 fid = FrechetInceptionDistance(feature=64)\n",
    "#                 real = torch.tensor(real_img,dtype=torch.uint8).cpu()\n",
    "#                 fake = torch.tensor(gen_img,dtype=torch.uint8).cpu()\n",
    "        \n",
    "#                 fid.update(real, real=True)\n",
    "#                 fid.update(fake, real=False)\n",
    "                \n",
    "#                 inception.update(fake)\n",
    "        \n",
    "#                 if i == 0:\n",
    "#                     is_s1,is_s2  = inception.compute()\n",
    "#                     fid_s = fid.compute()\n",
    "#                 else:\n",
    "#                     is_s1,is_s2 = inception.compute()\n",
    "#                     is_s1 += is_s1\n",
    "#                     is_s2 += is_s2\n",
    "                    \n",
    "#                     fid_s +=fid.compute()\n",
    "                    \n",
    "                    \n",
    "#                 if (i+1) % config.log_interval == 0: \n",
    "#                     print('Epoch [{}/{}] Batch [{}/{}] Discriminator fid: {} is1:{} is2:{}'.format(\n",
    "#                     epoch+1,\n",
    "#                     config.n_epoch,\n",
    "#                     i+1,\n",
    "#                     len(train_loader),\n",
    "#                     fid_s/(i+1),\n",
    "#                     is_s1/(i+1),\n",
    "#                     is_s2/(i+1)\n",
    "#                     ))\n",
    "  \n",
    "        if (i+1) % config.log_interval == 0:\n",
    "            g_loss_list.append(g_loss.item())\n",
    "            d_loss_list.append(d_loss.item())\n",
    "            print('Epoch [{}/{}] Batch [{}/{}] Discriminator loss: {:.4f} Generator loss: {:.4f}'.format(\n",
    "                epoch+1,\n",
    "                config.n_epoch,\n",
    "                i+1,\n",
    "                len(train_loader),\n",
    "                d_loss.item(),\n",
    "                g_loss.item()\n",
    "            ))\n",
    "                \n",
    "            \n",
    "    if (epoch+1) % config.save_interval == 0:\n",
    "        save_path = os.path.join(config.save_path, config.dataset, 'epoch_[{0:-03d}]_fid[].png'.format(\n",
    "            epoch+1,\n",
    "            #fid_s/(i+1)\n",
    "        ))\n",
    "        gen_img = config.denormalize(gen_img)\n",
    "        torchvision.utils.save_image(gen_img.data[:16], save_path, nrow=4, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fce0155e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# z = torch.randn((5, 100), device=config.device, dtype=torch.float32)\n",
    "\n",
    "# z, torch.min(z),torch.min(z[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0658ce",
   "metadata": {
    "id": "0e0658ce",
    "outputId": "f697deea-a400-44f8-8133-0bc0b179596c"
   },
   "outputs": [],
   "source": [
    "plt.title('GAN training loss on {} data'.format(config.dataset))\n",
    "plt.plot(g_loss_list, label='generator loss')\n",
    "plt.plot(d_loss_list, label='discriminator loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b18473b",
   "metadata": {
    "id": "3b18473b"
   },
   "source": [
    "## Qualitative results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1b0509",
   "metadata": {
    "id": "db1b0509",
    "outputId": "71f5ad53-0e15-4dd8-ac74-29a7126017ee",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "save_path = os.path.join(config.save_path, config.dataset)\n",
    "for image_path in os.listdir(save_path):\n",
    "    if image_path.endswith('.png'):\n",
    "        plt.figure(figsize=(5,5))\n",
    "        image = Image.open(os.path.join(save_path, image_path))\n",
    "        plt.title(image_path)\n",
    "        plt.imshow(image)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e4a959",
   "metadata": {
    "id": "1ee394e6"
   },
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "basis_3.8",
   "language": "python",
   "name": "basis_3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "e361de83e42006260aed2b055f8f04aac5dcd7e3eec4c7f8d8ccd6db537cc702"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
